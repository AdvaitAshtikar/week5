---
title: "Weekly Summary Template"
author: "Author Name"
title-block-banner: true
title-block-style: default
toc: true
# format: html
format: pdf
---

------------------------------------------------------------------------

## Tuesday, Feb 7

::: callout-important
## TIL

Include a *very brief* summary of what you learnt in this class here.

Today, I learnt the following concepts in class:

1.  Interpretation of regression coefficients
2.  Categorical Covariates
3.  Multiple Regression
    1.  Extension from SLR

    2.  Other Topics
:::

### Libraries Used

```{r}
library(tidyverse)
library(ISLR2)
library(cowplot)
library(kableExtra)
library(htmlwidgets)
```

### What is the interpretation of $\beta_0$ and $\beta_1$?

The regression model is given as follows:

$$
y_i = \beta_0 + \beta_1 * x_i + \epsilon_1
$$

where:

1.  $y_i$ are the response
2.  $x_i$ is the covariate
3.  $\epsilon_i$ is the error
4.  $\beta_0$ and $\beta_1$ are the regression coefficients
5.  $i = 1, 2, \dots, n$ are the indices for the observations

Interpretations for the regression coefficients are that $\beta_0$ is the intercept and $\beta_1$ is the slope.

Lets consider the following example using 'mtcars'

```{r}
library(ggplot2)

mtcars %>% head() %>% kable()
```

Consider the following relationships:

```{r}
x <- mtcars$hp
y <- mtcars$mpg

plot(x, y, pch=20, xlab="HP", ylab="MPG")
```

```{r}
model <- lm(y ~ x)
summary(model)
```

For the intercept this means that:

> A "hypothetical" car with 'hp = 0' will have 'mpg = 30.09' = $\beta_0$

Its more instructive to consider the interpretation of the slope:

For example, if we have a covariate $x_0$ then the expected value for $y(x_0)$ is given by

$$
y(x_0) = \beta_0 +\beta_1 x_0
$$

What is the expected value for $x_0 +1$ $$
y(x_0 + 1) = \beta_0 + \beta_1 \times (x_0 + 1)
\\ = \beta_0 + \beta_1 x_0 + \beta_1
\\= y(x_0) + \beta_1
\\above \implies \beta_1 = y(x_0 + 1) - y(x_0)
$$

### Categorical Covariates

So far we looked at *simple* linear regression models where both $x$ and $y$ are quantitative.

Lets confirm that 'cyl' is indeed categorical:

```{r}
mtcars$cyl
```

Another example we have is with the iris dataset:

```{r}
iris %>% head() %>% kable()
```

**Example:** We want to see if there is a relationship between 'species' and 'sepal.length'. How would we start the EDA?

```{r}
y <- iris$Sepal.Length
x <- iris$Species
boxplot(y ~ x, iris)
```

Lets run a linear regression model and see what the model output is going to look like:

```{r}
cat_model <- lm(Sepal.Length ~ Species, iris)
cat_model
```

Even if $x$ is categorical we can still write down the regression model as follows:

$$
y_i = \beta_0 +\beta_1 * x_i
$$

where $x_i \in \{setosa, versicolor, virginica \}$. This means that we end up with, (fundamentally) three different models

1.  $y_i = \beta_0 + \beta_1 * (x_i == )\space 'setosa'$
2.  $y_i = \beta_0 + \beta_1 * (x_i == )\space 'versicolor'$
3.  $y_i = \beta_0 + \beta_1 * (x_i == )\space 'virginica'$

Now, the interpretation for the coefficients are as follows:

#### Intercept

$\beta_0$ is the expected $y$ value when $x$ belongs to th base category. This is what the intercept is capturing.

#### Slopes

$\beta_1$ with the name 'Species.versicolor' represents the following:

'(Intercept)' = $y(x = \texttt{setosa})$

'Species.versicolor' = $y(x = \texttt{versicolor}) - y(x = \texttt{setosa})$

'Species.virginca' = $y(x = \texttt{virginca}) - y(x = \texttt{setosa})$

#### Reordering the factors

Lets say that we didn't want 'setosa' to be the baseline level, and, instead, we wanted 'virginica' to be the baseline level. How would we do this?

First, we're going to reorder/relevel the categorical covariate

```{r}
iris$Species # Before

iris$Species <- relevel(iris$Species, "virginica")
```

```{r}
iris$Species # After
```

Once we do the re-leveling, we can now run the regression model:

```{r}
new_cat_model <- lm(Sepal.Length ~ Species, iris)
new_cat_model
```

## Thursday, Feb 9

::: callout-important
## TIL

Include a *very brief* summary of what you learnt in this class here.

Today, I learnt the following concepts in class:

1.  Multiple Regression
:::

### Libraries

```{r}
library(plotly)
```

### Multiple Regression

This is the extension of simple linear regression to multiple covariates $X = [x_1 | x_2 | \dots | x_p]$, i.e.,

$$
y = \beta_0 +\beta_1 x_1 + \beta_2 x_2 + \dots \beta_p x_p + \epsilon
$$

In particular, the data looks like the following:

| $\mathbf y$ | $\mathbf x_1$ | $\mathbf x_2$ | $\dots$  | $\mathbf x_p$ |
|:-----------:|:-------------:|:-------------:|:--------:|:-------------:|
|   $y_{1}$   |   $x_{1,1}$   |   $x_{2,1}$   | $\dots$  |   $x_{3,1}$   |
|   $y_{2}$   |   $x_{1,2}$   |   $x_{2,2}$   | $\dots$  |   $x_{3,2}$   |
|   $y_{3}$   |   $x_{1,3}$   |   $x_{2,3}$   | $\dots$  |   $x_{3,3}$   |
|  $\vdots$   |   $\vdots$    |   $\vdots$    | $\ddots$ |   $\vdots$    |
|   $y_{n}$   |   $x_{1,n}$   |   $x_{2,n}$   | $\dots$  |   $x_{3,n}$   |

and, the full description of the model is as follows:

$$
y_i = \beta_0 + \beta_1 x_{1, i} + \beta_2 x_{2, i} + \dots + \beta_p x_{p, i} + \epsilon
$$ Consider the 'Credit' dataset:

```{r}
library(ISLR2)
attach(Credit)

df <- Credit %>%
  tibble()
df
```

and, we'll look at the following three columns: 'income, rating, limit'

```{r}
df3 <- df %>%
  select(Income, Rating, Limit)
df3
```

If we want to see how the credit limit is related too income and credit rating, we can visualize the following plot:

```{r}
fig <- plot_ly(df3, x = ~Income, y = ~Rating, z = ~Limit)
fig %>% add_markers()
```

The regression model is as follows:

```{r}
model <- lm(Limit ~ Income + Rating, df3)
model
```

**Q.** What does the regression model look like here?

```{r}
ranges <- df3 %>%
  select(Income, Rating) %>%
  colnames() %>%
  map(\(x) seq(0.1 * min(df3[x]), 1.1 * max(df3[x]), length.out = 50))

b <- model$coefficients
z <- outer(
  ranges[[1]],
  ranges[[2]],
  Vectorize(function(x2, x3) {
    b[1] + b[2] * x2 + b[3] * x3
  })
)

fig %>%
  add_surface(x = ranges[[1]], y = ranges[[2]], z = t(z), alpha = 0.3) %>%
  add_markers()
```

> **Q.** What is the interpretation for the coefficients?
>
> 1.  $\beta_0$ is the expected value of $y$ when $income = 0$ and $rating = 0$
> 2.  $\beta_1$ is saying that if $rating$ is held constant and $income$ changes by 1 unit, then the corresponding change in the 'limit' is $0.5573$
> 3.  $\beta_2$ is saying that if 'income' is held constant and 'rating' changes by $1$ unit, then the corresponding change in 'limit' is $14.771$.
>
> **Q.** What about the significance?
>
> ```{r}
> summary(model)
> ```
